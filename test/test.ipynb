{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Installation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check what will be installed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd .. && git log -n 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip uninstall -y wmfdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -e .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pyarrow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import wmfdata as wmf\n",
    "\n",
    "import findspark\n",
    "findspark.init(\"/usr/lib/spark2\")\n",
    "import pyspark\n",
    "\n",
    "def assert_dataframes_match(df1, df2):\n",
    "  assert df1.equals(df2)\n",
    "  assert df1.index.equals(df2.index)\n",
    "  assert df1.columns.equals(df2.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "COMMANDS_WITH_EMPTY_OUTPUT = [\n",
    "  \"DROP TABLE IF EXISTS neilpquinn.wmfdata_test_3\",\n",
    "  # Schema matches test_data_1\n",
    "  \"\"\"\n",
    "  CREATE TABLE `neilpquinn.wmfdata_test_3`(\n",
    "    `month` TIMESTAMP, \n",
    "    `wiki` STRING, \n",
    "    `user_id` BIGINT,\n",
    "    `user_name` STRING, \n",
    "    `edits` BIGINT,\n",
    "    `content_edits` BIGINT,\n",
    "    `user_registration` TIMESTAMP\n",
    "  )\n",
    "  \"\"\",\n",
    "  \"\"\"\n",
    "  SELECT *\n",
    "  FROM neilpquinn.wmfdata_test_3\n",
    "  \"\"\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_DATA_1 = pd.read_parquet(\"test_data_1.parquet\", engine=\"pyarrow\")\n",
    "\n",
    "spark = wmf.spark.get_session(type=\"local\", app_name=\"wmfdata-test\")\n",
    "current_directory = os.getcwd()\n",
    "spark_df = spark.read.load(f\"file://{current_directory}/test_data_1.parquet\")\n",
    "spark_df.write.mode(\"overwrite\").saveAsTable(\"neilpquinn.wmfdata_test_1\")\n",
    "\n",
    "TEST_DATA_1_QUERY = \"\"\"\n",
    "SELECT *\n",
    "FROM neilpquinn.wmfdata_test_1\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_DATA_2 = pd.read_csv(\"test_data_2.csv\")\n",
    "\n",
    "wmf.hive.load_csv(\n",
    "  \"test_data_2.csv\",\n",
    "  \"name string, iso_code string, economic_region string, maxmind_continent string\",\n",
    "  db_name=\"neilpquinn\",\n",
    "  table_name=\"wmfdata_test_2\"\n",
    ")\n",
    "\n",
    "TEST_DATA_2_QUERY = \"\"\"\n",
    "SELECT *\n",
    "FROM neilpquinn.wmfdata_test_2\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_1_via_hive = wmf.hive.run_cli(TEST_DATA_1_QUERY)\n",
    "assert_dataframes_match(TEST_DATA_1, test_data_1_via_hive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_2_via_hive = wmf.hive.run_cli(TEST_DATA_2_QUERY)\n",
    "assert_dataframes_match(TEST_DATA_2, test_data_2_via_hive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Any empty pandas data frame\n",
    "empty_output = wmf.hive.run_cli(COMMANDS_WITH_EMPTY_OUTPUT)\n",
    "assert empty_output.empty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_1_via_spark = wmf.spark.run(TEST_DATA_1_QUERY)\n",
    "assert_dataframes_match(TEST_DATA_1, test_data_1_via_spark)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MariaDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_tuples = TEST_DATA_1.itertuples(index=False, name=None)\n",
    "test_data_1_records = \",\\n\".join(\n",
    "  [str(t) for t in test_data_tuples]\n",
    ")\n",
    "\n",
    "CREATE_TABLE_SQL = \"\"\"\n",
    "CREATE OR REPLACE TABLE wmfdata_test_4 (\n",
    "  month VARCHAR(255),\n",
    "  wiki VARCHAR(255), \n",
    "  user_id BIGINT,\n",
    "  user_name VARCHAR(255), \n",
    "  edits BIGINT,\n",
    "  content_edits BIGINT,\n",
    "  user_registration VARCHAR(255)\n",
    "  )\n",
    "\"\"\"\n",
    "\n",
    "INSERT_RECORDS_SQL = f\"\"\"\n",
    "INSERT INTO\n",
    "wmfdata_test_4 \n",
    "VALUES\n",
    "{test_data_1_records}\n",
    "\"\"\"\n",
    "\n",
    "wmf.mariadb.run(\n",
    "  [CREATE_TABLE_SQL, INSERT_RECORDS_SQL], \n",
    "  dbs=[\"staging\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_1_via_mariadb = wmf.mariadb.run(\n",
    "  \"\"\"\n",
    "  SELECT *\n",
    "  FROM \n",
    "  wmfdata_test_4\n",
    "  \"\"\", \n",
    "  \"staging\"\n",
    ")\n",
    "\n",
    "assert_dataframes_match(TEST_DATA_1, test_data_1_via_mariadb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
